{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# How to run on GPU\n",
        "\n",
        "Step 1) Go to https://github.com/settings/tokens and get a token that can read your private repos\n",
        "\n",
        "Step 2) Clone this colab notebook and change the execution environment to GPU.\n",
        "\n",
        "Step 3) Install python 3.8\n",
        "\n",
        "Step 4) Clone and install your code.\n",
        "\n",
        "Step 5) Run the command-line code for training."
      ],
      "metadata": {
        "id": "z4pWhxZCyMQ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3: Install python 3.8\n",
        "Run the cell below without editing it."
      ],
      "metadata": {
        "id": "BTzMYZB5yynZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lciKNd6myIjl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd634367-da95-46d6-b65f-802513ca681f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,113 kB]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,482 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,453 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,279 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,383 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,718 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,428 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,165 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,613 kB]\n",
            "Fetched 27.0 MB in 4s (6,365 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib mailcap mime-support\n",
            "  python3.8-minimal\n",
            "Suggested packages:\n",
            "  python3.8-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib mailcap mime-support python3.8\n",
            "  python3.8-minimal\n",
            "0 upgraded, 6 newly installed, 0 to remove and 58 not upgraded.\n",
            "Need to get 5,103 kB of archives.\n",
            "After this operation, 18.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 mailcap all 3.70+nmu1ubuntu1 [23.8 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 mime-support all 3.66 [3,696 B]\n",
            "Get:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-minimal amd64 3.8.20-1+jammy1 [796 kB]\n",
            "Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-minimal amd64 3.8.20-1+jammy1 [2,023 kB]\n",
            "Get:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-stdlib amd64 3.8.20-1+jammy1 [1,817 kB]\n",
            "Get:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8 amd64 3.8.20-1+jammy1 [440 kB]\n",
            "Fetched 5,103 kB in 3s (1,734 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 6.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython3.8-minimal:amd64.\n",
            "(Reading database ... 123629 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libpython3.8-minimal_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-minimal:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-minimal.\n",
            "Preparing to unpack .../1-python3.8-minimal_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8-minimal (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package mailcap.\n",
            "Preparing to unpack .../2-mailcap_3.70+nmu1ubuntu1_all.deb ...\n",
            "Unpacking mailcap (3.70+nmu1ubuntu1) ...\n",
            "Selecting previously unselected package mime-support.\n",
            "Preparing to unpack .../3-mime-support_3.66_all.deb ...\n",
            "Unpacking mime-support (3.66) ...\n",
            "Selecting previously unselected package libpython3.8-stdlib:amd64.\n",
            "Preparing to unpack .../4-libpython3.8-stdlib_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-stdlib:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8.\n",
            "Preparing to unpack .../5-python3.8_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8 (3.8.20-1+jammy1) ...\n",
            "Setting up libpython3.8-minimal:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8-minimal (3.8.20-1+jammy1) ...\n",
            "Setting up mailcap (3.70+nmu1ubuntu1) ...\n",
            "Setting up mime-support (3.66) ...\n",
            "Setting up libpython3.8-stdlib:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8 (3.8.20-1+jammy1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2222k  100 2222k    0     0  11.3M      0 --:--:-- --:--:-- --:--:-- 11.3M\n",
            "Traceback (most recent call last):\n",
            "  File \"get-pip.py\", line 28535, in <module>\n",
            "    main()\n",
            "  File \"get-pip.py\", line 137, in main\n",
            "    bootstrap(tmpdir=tmpdir)\n",
            "  File \"get-pip.py\", line 113, in bootstrap\n",
            "    monkeypatch_for_cert(tmpdir)\n",
            "  File \"get-pip.py\", line 94, in monkeypatch_for_cert\n",
            "    from pip._internal.commands.install import InstallCommand\n",
            "  File \"<frozen zipimport>\", line 259, in load_module\n",
            "  File \"/tmp/tmpz3yr80uo/pip.zip/pip/_internal/commands/__init__.py\", line 9, in <module>\n",
            "  File \"<frozen zipimport>\", line 259, in load_module\n",
            "  File \"/tmp/tmpz3yr80uo/pip.zip/pip/_internal/cli/base_command.py\", line 15, in <module>\n",
            "  File \"<frozen zipimport>\", line 259, in load_module\n",
            "  File \"/tmp/tmpz3yr80uo/pip.zip/pip/_internal/cli/cmdoptions.py\", line 24, in <module>\n",
            "  File \"<frozen zipimport>\", line 259, in load_module\n",
            "  File \"/tmp/tmpz3yr80uo/pip.zip/pip/_internal/cli/parser.py\", line 12, in <module>\n",
            "  File \"<frozen zipimport>\", line 259, in load_module\n",
            "  File \"/tmp/tmpz3yr80uo/pip.zip/pip/_internal/configuration.py\", line 26, in <module>\n",
            "  File \"<frozen zipimport>\", line 259, in load_module\n",
            "  File \"/tmp/tmpz3yr80uo/pip.zip/pip/_internal/utils/logging.py\", line 29, in <module>\n",
            "  File \"<frozen zipimport>\", line 259, in load_module\n",
            "  File \"/tmp/tmpz3yr80uo/pip.zip/pip/_internal/utils/misc.py\", line 41, in <module>\n",
            "  File \"<frozen zipimport>\", line 259, in load_module\n",
            "  File \"/tmp/tmpz3yr80uo/pip.zip/pip/_internal/locations/__init__.py\", line 66, in <module>\n",
            "  File \"<frozen zipimport>\", line 259, in load_module\n",
            "  File \"/tmp/tmpz3yr80uo/pip.zip/pip/_internal/locations/_distutils.py\", line 20, in <module>\n",
            "ModuleNotFoundError: No module named 'distutils.cmd'\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get update -y\n",
        "!sudo apt-get install python3.8\n",
        "!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n",
        "!python3.8 get-pip.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 4: Clone and install your code\n",
        "First we need to set some environment variables. Get your github API token and MLE repo username and put them into the below variables."
      ],
      "metadata": {
        "id": "guhMlPoey3zE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ['TOKEN'] = userdata.get('github_api_token')"
      ],
      "metadata": {
        "id": "sBzUIPNorKoX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %env TOKEN=token\n",
        "%env USER=mitkrieg"
      ],
      "metadata": {
        "id": "wmmAQK12zJJP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "760591c6-e6c5-4473-da40-3954bb6056c8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: USER=mitkrieg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the below code. Editing should not be necessary."
      ],
      "metadata": {
        "id": "-JZt2xZwzS2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TOKEN = %env TOKEN\n",
        "USER = %env USER\n",
        "%env DIR=mod3-$USER\n",
        "DIR = %env DIR\n",
        "\n",
        "# !echo https://$TOKEN@github.com/Cornell-Tech-ML/$DIR\n",
        "\n",
        "!git clone -b master --single-branch https://$TOKEN@github.com/Cornell-Tech-ML/$DIR\n",
        "!cd $DIR; pip3 install -r requirements.txt; pip3 install -r requirements.extra.txt; pip3 install ."
      ],
      "metadata": {
        "id": "ZYb6KtYFzJjD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7f6160c-989e-459c-849b-205082346aa9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: DIR=mod3-mitkrieg\n",
            "Cloning into 'mod3-mitkrieg'...\n",
            "remote: Enumerating objects: 183, done.\u001b[K\n",
            "remote: Counting objects: 100% (114/114), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "Receiving objects: 100% (183/183), 84.37 KiB | 14.06 MiB/s, done.\n",
            "remote: Total 183 (delta 80), reused 77 (delta 74), pack-reused 69 (from 1)\u001b[K\n",
            "Resolving deltas: 100% (99/99), done.\n",
            "Collecting colorama==0.4.3 (from -r requirements.txt (line 1))\n",
            "  Downloading colorama-0.4.3-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Collecting hypothesis==6.54 (from -r requirements.txt (line 2))\n",
            "  Downloading hypothesis-6.54.0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: numba==0.60 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.60.0)\n",
            "Collecting numpy==2.0.0 (from -r requirements.txt (line 4))\n",
            "  Downloading numpy-2.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pre-commit==2.20.0 (from -r requirements.txt (line 5))\n",
            "  Downloading pre_commit-2.20.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting pytest==8.3.2 (from -r requirements.txt (line 6))\n",
            "  Downloading pytest-8.3.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting pytest-env (from -r requirements.txt (line 7))\n",
            "  Downloading pytest_env-1.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting pytest-runner==5.2 (from -r requirements.txt (line 8))\n",
            "  Downloading pytest_runner-5.2-py2.py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (4.12.2)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from hypothesis==6.54->-r requirements.txt (line 2)) (24.2.0)\n",
            "Collecting sortedcontainers<3.0.0,>=2.1.0 (from hypothesis==6.54->-r requirements.txt (line 2))\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from hypothesis==6.54->-r requirements.txt (line 2)) (1.2.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba==0.60->-r requirements.txt (line 3)) (0.43.0)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit==2.20.0->-r requirements.txt (line 5))\n",
            "  Downloading cfgv-3.4.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit==2.20.0->-r requirements.txt (line 5))\n",
            "  Downloading identify-2.6.2-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting nodeenv>=0.11.1 (from pre-commit==2.20.0->-r requirements.txt (line 5))\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from pre-commit==2.20.0->-r requirements.txt (line 5)) (6.0.2)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pre-commit==2.20.0->-r requirements.txt (line 5)) (0.10.2)\n",
            "Collecting virtualenv>=20.0.8 (from pre-commit==2.20.0->-r requirements.txt (line 5))\n",
            "  Downloading virtualenv-20.27.1-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest==8.3.2->-r requirements.txt (line 6)) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest==8.3.2->-r requirements.txt (line 6)) (24.2)\n",
            "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/dist-packages (from pytest==8.3.2->-r requirements.txt (line 6)) (1.5.0)\n",
            "Requirement already satisfied: tomli>=1 in /usr/local/lib/python3.10/dist-packages (from pytest==8.3.2->-r requirements.txt (line 6)) (2.1.0)\n",
            "INFO: pip is looking at multiple versions of pytest-env to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting pytest-env (from -r requirements.txt (line 7))\n",
            "  Downloading pytest_env-1.1.4-py3-none-any.whl.metadata (5.3 kB)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.0.8->pre-commit==2.20.0->-r requirements.txt (line 5))\n",
            "  Downloading distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: filelock<4,>=3.12.2 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.0.8->pre-commit==2.20.0->-r requirements.txt (line 5)) (3.16.1)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.0.8->pre-commit==2.20.0->-r requirements.txt (line 5)) (4.3.6)\n",
            "Downloading colorama-0.4.3-py2.py3-none-any.whl (15 kB)\n",
            "Downloading hypothesis-6.54.0-py3-none-any.whl (389 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.6/389.6 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pre_commit-2.20.0-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.5/199.5 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest-8.3.2-py3-none-any.whl (341 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytest_runner-5.2-py2.py3-none-any.whl (6.8 kB)\n",
            "Downloading pytest_env-1.1.4-py3-none-any.whl (6.2 kB)\n",
            "Downloading cfgv-3.4.0-py2.py3-none-any.whl (7.2 kB)\n",
            "Downloading identify-2.6.2-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.0/99.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading virtualenv-20.27.1-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading distlib-0.3.9-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sortedcontainers, distlib, virtualenv, pytest-runner, pytest, numpy, nodeenv, identify, hypothesis, colorama, cfgv, pytest-env, pre-commit\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 8.3.3\n",
            "    Uninstalling pytest-8.3.3:\n",
            "      Successfully uninstalled pytest-8.3.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cupy-cuda12x 12.2.0 requires numpy<1.27,>=1.20, but you have numpy 2.0.0 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.0.0 which is incompatible.\n",
            "langchain 0.3.7 requires numpy<2,>=1; python_version < \"3.12\", but you have numpy 2.0.0 which is incompatible.\n",
            "matplotlib 3.8.0 requires numpy<2,>=1.21, but you have numpy 2.0.0 which is incompatible.\n",
            "pytensor 2.25.5 requires numpy<2,>=1.17.0, but you have numpy 2.0.0 which is incompatible.\n",
            "tensorflow 2.17.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.0.0 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cfgv-3.4.0 colorama-0.4.3 distlib-0.3.9 hypothesis-6.54.0 identify-2.6.2 nodeenv-1.9.1 numpy-2.0.0 pre-commit-2.20.0 pytest-8.3.2 pytest-env-1.1.4 pytest-runner-5.2 sortedcontainers-2.4.0 virtualenv-20.27.1\n",
            "Requirement already satisfied: altair==4.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.extra.txt (line 1)) (4.2.2)\n",
            "Collecting datasets==2.4.0 (from -r requirements.extra.txt (line 2))\n",
            "  Downloading datasets-2.4.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting embeddings==0.0.8 (from -r requirements.extra.txt (line 3))\n",
            "  Downloading embeddings-0.0.8-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting networkx==3.3 (from -r requirements.extra.txt (line 4))\n",
            "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting plotly==4.14.3 (from -r requirements.extra.txt (line 5))\n",
            "  Downloading plotly-4.14.3-py2.py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting pydot==1.4.1 (from -r requirements.extra.txt (line 6))\n",
            "  Downloading pydot-1.4.1-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting python-mnist (from -r requirements.extra.txt (line 7))\n",
            "  Downloading python_mnist-0.7-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting streamlit==1.12.0 (from -r requirements.extra.txt (line 8))\n",
            "  Downloading streamlit-1.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting streamlit-ace (from -r requirements.extra.txt (line 9))\n",
            "  Downloading streamlit_ace-0.1.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.extra.txt (line 10)) (2.5.1+cu121)\n",
            "Collecting watchdog==1.0.2 (from -r requirements.extra.txt (line 11))\n",
            "  Downloading watchdog-1.0.2-py3-none-manylinux2014_x86_64.whl.metadata (23 kB)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.extra.txt (line 1)) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.extra.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.extra.txt (line 1)) (4.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.extra.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: pandas>=0.18 in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.extra.txt (line 1)) (2.2.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair==4.2.2->-r requirements.extra.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 2)) (17.0.0)\n",
            "Collecting dill<0.3.6 (from datasets==2.4.0->-r requirements.extra.txt (line 2))\n",
            "  Downloading dill-0.3.5.1-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 2)) (4.66.6)\n",
            "Collecting xxhash (from datasets==2.4.0->-r requirements.extra.txt (line 2))\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets==2.4.0->-r requirements.extra.txt (line 2))\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.11.1->datasets==2.4.0->-r requirements.extra.txt (line 2)) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 2)) (3.11.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 2)) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.4.0->-r requirements.extra.txt (line 2)) (24.2)\n",
            "Collecting responses<0.19 (from datasets==2.4.0->-r requirements.extra.txt (line 2))\n",
            "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting retrying>=1.3.3 (from plotly==4.14.3->-r requirements.extra.txt (line 5))\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from plotly==4.14.3->-r requirements.extra.txt (line 5)) (1.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot==1.4.1->-r requirements.extra.txt (line 6)) (3.2.0)\n",
            "Requirement already satisfied: blinker>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (1.9.0)\n",
            "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (5.5.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (8.1.7)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (8.5.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (11.0.0)\n",
            "Collecting protobuf<4,>=3.12 (from streamlit==1.12.0->-r requirements.extra.txt (line 8))\n",
            "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
            "Collecting pydeck>=0.1.dev5 (from streamlit==1.12.0->-r requirements.extra.txt (line 8))\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting pympler>=0.9 (from streamlit==1.12.0->-r requirements.extra.txt (line 8))\n",
            "  Downloading Pympler-1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (2.8.2)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (13.9.4)\n",
            "Collecting semver (from streamlit==1.12.0->-r requirements.extra.txt (line 8))\n",
            "  Downloading semver-3.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (0.10.2)\n",
            "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (6.3.3)\n",
            "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (4.12.2)\n",
            "Requirement already satisfied: tzlocal>=1.1 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (5.2)\n",
            "Collecting validators>=0.2 (from streamlit==1.12.0->-r requirements.extra.txt (line 8))\n",
            "  Downloading validators-0.34.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: gitpython!=3.1.19 in /usr/local/lib/python3.10/dist-packages (from streamlit==1.12.0->-r requirements.extra.txt (line 8)) (3.1.43)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.extra.txt (line 10)) (3.16.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.extra.txt (line 10)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->-r requirements.extra.txt (line 10)) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 2)) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 2)) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 2)) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 2)) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 2)) (1.17.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.4.0->-r requirements.extra.txt (line 2)) (4.0.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19->streamlit==1.12.0->-r requirements.extra.txt (line 8)) (4.0.11)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets==2.4.0->-r requirements.extra.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->streamlit==1.12.0->-r requirements.extra.txt (line 8)) (3.21.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair==4.2.2->-r requirements.extra.txt (line 1)) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair==4.2.2->-r requirements.extra.txt (line 1)) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair==4.2.2->-r requirements.extra.txt (line 1)) (0.21.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18->altair==4.2.2->-r requirements.extra.txt (line 1)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.18->altair==4.2.2->-r requirements.extra.txt (line 1)) (2024.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair==4.2.2->-r requirements.extra.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.4.0->-r requirements.extra.txt (line 2)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.4.0->-r requirements.extra.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.4.0->-r requirements.extra.txt (line 2)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.4.0->-r requirements.extra.txt (line 2)) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->streamlit==1.12.0->-r requirements.extra.txt (line 8)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->streamlit==1.12.0->-r requirements.extra.txt (line 8)) (2.18.0)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from datasets==2.4.0->-r requirements.extra.txt (line 2))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl.metadata (6.6 kB)\n",
            "  Downloading multiprocess-0.70.13-py310-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit==1.12.0->-r requirements.extra.txt (line 8)) (5.0.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->streamlit==1.12.0->-r requirements.extra.txt (line 8)) (0.1.2)\n",
            "Downloading datasets-2.4.0-py3-none-any.whl (365 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading embeddings-0.0.8-py3-none-any.whl (12 kB)\n",
            "Downloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading plotly-4.14.3-py2.py3-none-any.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydot-1.4.1-py2.py3-none-any.whl (19 kB)\n",
            "Downloading streamlit-1.12.0-py2.py3-none-any.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m116.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-1.0.2-py3-none-manylinux2014_x86_64.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.6/72.6 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_mnist-0.7-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading streamlit_ace-0.1.1-py3-none-any.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m94.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.8/95.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Pympler-1.1-py3-none-any.whl (165 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.8/165.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading validators-0.34.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.13-py310-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-mnist, xxhash, watchdog, validators, semver, retrying, pympler, pydot, protobuf, networkx, dill, responses, pydeck, plotly, multiprocess, embeddings, streamlit, datasets, streamlit-ace\n",
            "  Attempting uninstall: pydot\n",
            "    Found existing installation: pydot 3.0.2\n",
            "    Uninstalling pydot-3.0.2:\n",
            "      Successfully uninstalled pydot-3.0.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 5.24.1\n",
            "    Uninstalling plotly-5.24.1:\n",
            "      Successfully uninstalled plotly-5.24.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\n",
            "tensorflow 2.17.1 requires numpy<2.0.0,>=1.23.5; python_version <= \"3.11\", but you have numpy 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.4.0 dill-0.3.5.1 embeddings-0.0.8 multiprocess-0.70.13 networkx-3.3 plotly-4.14.3 protobuf-3.20.3 pydeck-0.9.1 pydot-1.4.1 pympler-1.1 python-mnist-0.7 responses-0.18.0 retrying-1.3.4 semver-3.0.2 streamlit-1.12.0 streamlit-ace-0.1.1 validators-0.34.0 watchdog-1.0.2 xxhash-3.5.0\n",
            "Processing /content/mod3-mitkrieg\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: minitorch\n",
            "  Building wheel for minitorch (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for minitorch: filename=minitorch-0.5-py2.py3-none-any.whl size=31981 sha256=f8270a062dc16ecd7f712beff6b4c67b8337b099e71ba2ccac498aa870476483\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/6b/2a/063d474e8731b9cbe4b0be9fdce106072571ad681f2b7be1f1\n",
            "Successfully built minitorch\n",
            "Installing collected packages: minitorch\n",
            "Successfully installed minitorch-0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import minitorch\n",
        "t = minitorch.tensor([\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9]\n",
        "])\n",
        "t"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6PCPjzNejaC",
        "outputId": "42e6f456-6c6a-4339-aee6-f97fce3612af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[\n",
              "\t[1.00 2.00 3.00]\n",
              "\t[4.00 5.00 6.00]\n",
              "\t[7.00 8.00 9.00]]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "minitorch.fast_ops.FastOps.matrix_multiply(t,t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6k1wGUEermA",
        "outputId": "58869c5d-f801-4790-835e-6e209a3a9d5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[\n",
              "\t[30.00 36.00 42.00]\n",
              "\t[66.00 81.00 96.00]\n",
              "\t[102.00 126.00 150.00]]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "minitorch.cuda_ops.CudaOps.matrix_multiply(t,t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUZtVR0ItpFQ",
        "outputId": "e0b0a332-7d84-4254-c6e6-bdaf5b11b128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[\n",
              "\t[30.00 36.00 42.00]\n",
              "\t[66.00 81.00 96.00]\n",
              "\t[102.00 126.00 150.00]]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Is-S3LSQf6bk",
        "outputId": "7bf8ea2d-46e2-48e7-f2c4-55ba267cdd43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "get-pip.py  mod3-mitkrieg  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pytest mod3-mitkrieg/tests/ -m task3_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okPG5bjzho5S",
        "outputId": "e5830806-aeec-4345-fcb7-d79275c860ce"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-8.3.2, pluggy-1.5.0\n",
            "rootdir: /content/mod3-mitkrieg\n",
            "configfile: pyproject.toml\n",
            "plugins: env-1.1.4, hypothesis-6.54.0, typeguard-4.4.1, anyio-3.7.1\n",
            "collected 117 items / 115 deselected / 2 selected                                                  \u001b[0m\n",
            "\n",
            "mod3-mitkrieg/tests/test_tensor_general.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                                [100%]\u001b[0m\n",
            "\n",
            "\u001b[32m================================ \u001b[32m\u001b[1m2 passed\u001b[0m, \u001b[33m115 deselected\u001b[0m\u001b[32m in 21.27s\u001b[0m\u001b[32m ================================\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pytest mod3-mitkrieg/tests/ -m task3_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otuX2Xrtfztg",
        "outputId": "9a2b65be-5bf3-4007-cbff-a67ff7c699dd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-8.3.2, pluggy-1.5.0\n",
            "rootdir: /content/mod3-mitkrieg\n",
            "configfile: pyproject.toml\n",
            "plugins: env-1.1.4, hypothesis-6.54.0, typeguard-4.4.1, anyio-3.7.1\n",
            "collected 117 items / 60 deselected / 57 selected                                                  \u001b[0m\n",
            "\n",
            "mod3-mitkrieg/tests/test_tensor_general.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33m [ 85%]\n",
            "\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33m                                                                                     [100%]\u001b[0m\n",
            "\n",
            "\u001b[33m========================================= warnings summary =========================================\u001b[0m\n",
            "tests/test_tensor_general.py: 16 warnings\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py: 4274 warnings\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py: 12 warnings\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_one_args[cuda-fn1]\n",
            "tests/test_tensor_general.py::test_one_derivative[cuda-fn0]\n",
            "tests/test_tensor_general.py::test_one_derivative[cuda-fn10]\n",
            "tests/test_tensor_general.py::test_sum_practice2\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 3 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_one_derivative[cuda-fn0]\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_one_derivative[cuda-fn0]\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 18 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_one_derivative[cuda-fn0]\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 6 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_one_derivative[cuda-fn0]\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 12 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_one_derivative[cuda-fn0]\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 8 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_one_derivative[cuda-fn0]\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 27 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_one_derivative[cuda-fn0]\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 9 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_sum_practice_other_dims\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
            "\u001b[33m=================== \u001b[32m57 passed\u001b[0m, \u001b[33m\u001b[1m60 deselected\u001b[0m, \u001b[33m\u001b[1m4314 warnings\u001b[0m\u001b[33m in 277.40s (0:04:37)\u001b[0m\u001b[33m ===================\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = minitorch.tensor(\n",
        "    [\n",
        "\t[\n",
        "\t\t[0.00, 0.00],\n",
        "\t\t[0.00, 0.00]],\n",
        "\t[\n",
        "\t\t[0.00, 0.00],\n",
        "\t\t[0.00, 0.00]]\n",
        " ]\n",
        ")\n",
        "b = minitorch.tensor([\n",
        "\t[\n",
        "\t\t[0.00, 0.00],\n",
        "\t\t[0.00, 0.00]],\n",
        "\t[\n",
        "\t\t[0.00, 0.00],\n",
        "\t\t[0.00, 1.00]]]\n",
        ")\n",
        "z = minitorch.fast_ops.FastOps.matrix_multiply(a, b)\n",
        "z\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJpyCJzO7F-L",
        "outputId": "4db23e70-d5e3-461f-e4d4-99d4100b8038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[\n",
              "\t[\n",
              "\t\t[0.00 0.00]\n",
              "\t\t[0.00 0.00]]\n",
              "\t[\n",
              "\t\t[0.00 0.00]\n",
              "\t\t[0.00 0.00]]]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = minitorch.cuda_ops.CudaOps.matrix_multiply(a, b)\n",
        "k\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8exI7-3S7qr2",
        "outputId": "dacceb4f-0db8-4d2f-c0ae-e4c66662e82d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\n",
              "[\n",
              "\t[\n",
              "\t\t[0.00 0.00]\n",
              "\t\t[0.00 0.00]]\n",
              "\t[\n",
              "\t\t[0.00 0.00]\n",
              "\t\t[0.00 0.00]]]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pytest mod3-mitkrieg/tests/ -m task3_4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZtXwk1UvRfC",
        "outputId": "3d67d6d7-8711-4205-f001-58490d0ed25c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m======================================= test session starts ========================================\u001b[0m\n",
            "platform linux -- Python 3.10.12, pytest-8.3.2, pluggy-1.5.0\n",
            "rootdir: /content/mod3-mitkrieg\n",
            "configfile: pyproject.toml\n",
            "plugins: env-1.1.4, hypothesis-6.54.0, typeguard-4.4.1, anyio-3.7.1\n",
            "collected 117 items / 110 deselected / 7 selected                                                  \u001b[0m\n",
            "\n",
            "mod3-mitkrieg/tests/test_tensor_general.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[33m                                           [100%]\u001b[0m\n",
            "\n",
            "\u001b[33m========================================= warnings summary =========================================\u001b[0m\n",
            "tests/test_tensor_general.py::test_mul_practice1\n",
            "tests/test_tensor_general.py::test_mul_practice3\n",
            "tests/test_tensor_general.py::test_mul_practice3\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py: 111 warnings\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_mul_practice4\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 35 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_mul_practice4\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_mul_practice5\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 8 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 12 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 3 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 24 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 6 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 64 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 36 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 48 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 5 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 27 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "tests/test_tensor_general.py::test_bmm[cuda]\n",
            "  /usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 18 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "    warn(NumbaPerformanceWarning(msg))\n",
            "\n",
            "-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n",
            "\u001b[33m========================= \u001b[32m7 passed\u001b[0m, \u001b[33m\u001b[1m110 deselected\u001b[0m, \u001b[33m\u001b[1m140 warnings\u001b[0m\u001b[33m in 12.50s\u001b[0m\u001b[33m =========================\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd $DIR; pwd; python3 timing.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXQwYAu2L3hK",
        "outputId": "a2e0ae90-0929-4a51-fcf9-ff1052133f50"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mod3-mitkrieg\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "Running size 64\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 8 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "{'fast': np.float64(0.0036759376525878906), 'gpu': np.float64(0.006918589274088542)}\n",
            "Running size 128\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "{'fast': np.float64(0.016693751017252605), 'gpu': np.float64(0.01602061589558919)}\n",
            "Running size 256\n",
            "{'fast': np.float64(0.10438330968221028), 'gpu': np.float64(0.054287115732828774)}\n",
            "Running size 512\n",
            "{'fast': np.float64(1.2272052764892578), 'gpu': np.float64(0.31065837542215985)}\n",
            "Running size 1024\n",
            "{'fast': np.float64(7.979773600896199), 'gpu': np.float64(1.0128754774729412)}\n",
            "\n",
            "Timing summary\n",
            "Size: 64\n",
            "    fast: 0.00368\n",
            "    gpu: 0.00692\n",
            "Size: 128\n",
            "    fast: 0.01669\n",
            "    gpu: 0.01602\n",
            "Size: 256\n",
            "    fast: 0.10438\n",
            "    gpu: 0.05429\n",
            "Size: 512\n",
            "    fast: 1.22721\n",
            "    gpu: 0.31066\n",
            "Size: 1024\n",
            "    fast: 7.97977\n",
            "    gpu: 1.01288\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you update your code, you can re-pull the repo by running this cell."
      ],
      "metadata": {
        "id": "E2xn5AhUzaW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd $DIR; pwd; git pull origin master; pip3 install --force-reinstall --no-cache-dir ."
      ],
      "metadata": {
        "id": "GywpmTnozf26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e82a3632-ffc6-4f71-ceb5-b4b9f77b8e21"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/mod3-mitkrieg\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 5 (delta 3), reused 5 (delta 3), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (5/5), 964 bytes | 964.00 KiB/s, done.\n",
            "From https://github.com/Cornell-Tech-ML/mod3-mitkrieg\n",
            " * branch            master     -> FETCH_HEAD\n",
            "   f5fbb84..f441a0d  master     -> origin/master\n",
            "Updating f5fbb84..f441a0d\n",
            "Fast-forward\n",
            " project/run_fast_tensor.py |  2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " timing.py                  | 58 \u001b[32m++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[m\n",
            " 2 files changed, 59 insertions(+), 1 deletion(-)\n",
            " create mode 100644 timing.py\n",
            "Processing /content/mod3-mitkrieg\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: minitorch\n",
            "  Building wheel for minitorch (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for minitorch: filename=minitorch-0.5-py2.py3-none-any.whl size=31751 sha256=67ba38a92618aab8f3d36af170c33ac6f8b3b410704ef638c89de8e058b716bd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wzzdkafk/wheels/46/6b/2a/063d474e8731b9cbe4b0be9fdce106072571ad681f2b7be1f1\n",
            "Successfully built minitorch\n",
            "Installing collected packages: minitorch\n",
            "  Attempting uninstall: minitorch\n",
            "    Found existing installation: minitorch 0.5\n",
            "    Uninstalling minitorch-0.5:\n",
            "      Successfully uninstalled minitorch-0.5\n",
            "Successfully installed minitorch-0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 5: Run the training command"
      ],
      "metadata": {
        "id": "qufLzTGmzs1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple"
      ],
      "metadata": {
        "id": "3xTSyOFpzh1x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd $DIR; PYTHONPATH=/content/$DIR python3 project/run_fast_tensor.py --BACKEND cpu --HIDDEN 100 --DATASET split --RATE 0.05"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxlG06RJAhe6",
        "outputId": "db1fa23c-b324-452f-d1d8-4258374f3413"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:     0 || Loss:  8.32548 || Correct    25 || Time per epoch:  18.39554\n",
            "Epoch:    10 || Loss:  6.47043 || Correct    40 || Time per epoch:  0.09881\n",
            "Epoch:    20 || Loss:  3.99787 || Correct    39 || Time per epoch:  0.09808\n",
            "Epoch:    30 || Loss:  2.95462 || Correct    39 || Time per epoch:  0.09782\n",
            "Epoch:    40 || Loss:  5.75990 || Correct    46 || Time per epoch:  0.09822\n",
            "Epoch:    50 || Loss:  2.24706 || Correct    48 || Time per epoch:  0.14127\n",
            "Epoch:    60 || Loss:  1.54707 || Correct    44 || Time per epoch:  0.15890\n",
            "Epoch:    70 || Loss:  2.59027 || Correct    49 || Time per epoch:  0.09943\n",
            "Epoch:    80 || Loss:  3.07012 || Correct    49 || Time per epoch:  0.10017\n",
            "Epoch:    90 || Loss:  3.73035 || Correct    45 || Time per epoch:  0.09817\n",
            "Epoch:   100 || Loss:  2.40822 || Correct    50 || Time per epoch:  0.09741\n",
            "Epoch:   110 || Loss:  2.12735 || Correct    49 || Time per epoch:  0.09832\n",
            "Epoch:   120 || Loss:  1.31102 || Correct    50 || Time per epoch:  0.09887\n",
            "Epoch:   130 || Loss:  0.48581 || Correct    48 || Time per epoch:  0.09799\n",
            "Epoch:   140 || Loss:  2.67849 || Correct    46 || Time per epoch:  0.09762\n",
            "Epoch:   150 || Loss:  0.86275 || Correct    48 || Time per epoch:  0.09803\n",
            "Epoch:   160 || Loss:  1.35992 || Correct    50 || Time per epoch:  0.09761\n",
            "Epoch:   170 || Loss:  0.99190 || Correct    50 || Time per epoch:  0.17720\n",
            "Epoch:   180 || Loss:  0.74015 || Correct    48 || Time per epoch:  0.12902\n",
            "Epoch:   190 || Loss:  3.16690 || Correct    46 || Time per epoch:  0.09795\n",
            "Epoch:   200 || Loss:  1.68249 || Correct    50 || Time per epoch:  0.09778\n",
            "Epoch:   210 || Loss:  0.82470 || Correct    50 || Time per epoch:  0.09736\n",
            "Epoch:   220 || Loss:  0.88740 || Correct    50 || Time per epoch:  0.10204\n",
            "Epoch:   230 || Loss:  0.74309 || Correct    49 || Time per epoch:  0.09836\n",
            "Epoch:   240 || Loss:  0.90257 || Correct    50 || Time per epoch:  0.09738\n",
            "Epoch:   250 || Loss:  0.85901 || Correct    50 || Time per epoch:  0.09770\n",
            "Epoch:   260 || Loss:  0.62612 || Correct    50 || Time per epoch:  0.09770\n",
            "Epoch:   270 || Loss:  0.45352 || Correct    49 || Time per epoch:  0.09899\n",
            "Epoch:   280 || Loss:  0.62163 || Correct    50 || Time per epoch:  0.13472\n",
            "Epoch:   290 || Loss:  0.10163 || Correct    49 || Time per epoch:  0.16312\n",
            "Epoch:   300 || Loss:  0.36479 || Correct    50 || Time per epoch:  0.09711\n",
            "Epoch:   310 || Loss:  0.48168 || Correct    50 || Time per epoch:  0.09712\n",
            "Epoch:   320 || Loss:  0.71765 || Correct    50 || Time per epoch:  0.09764\n",
            "Epoch:   330 || Loss:  0.74919 || Correct    50 || Time per epoch:  0.09802\n",
            "Epoch:   340 || Loss:  0.96047 || Correct    50 || Time per epoch:  0.09848\n",
            "Epoch:   350 || Loss:  0.52161 || Correct    50 || Time per epoch:  0.09754\n",
            "Epoch:   360 || Loss:  0.31385 || Correct    50 || Time per epoch:  0.09812\n",
            "Epoch:   370 || Loss:  0.31923 || Correct    50 || Time per epoch:  0.09864\n",
            "Epoch:   380 || Loss:  0.30227 || Correct    50 || Time per epoch:  0.09719\n",
            "Epoch:   390 || Loss:  1.00093 || Correct    50 || Time per epoch:  0.09703\n",
            "Epoch:   400 || Loss:  0.76221 || Correct    50 || Time per epoch:  0.16934\n",
            "Epoch:   410 || Loss:  0.08206 || Correct    50 || Time per epoch:  0.13446\n",
            "Epoch:   420 || Loss:  0.52891 || Correct    50 || Time per epoch:  0.09726\n",
            "Epoch:   430 || Loss:  0.38505 || Correct    50 || Time per epoch:  0.09814\n",
            "Epoch:   440 || Loss:  0.23398 || Correct    50 || Time per epoch:  0.09814\n",
            "Epoch:   450 || Loss:  0.23576 || Correct    50 || Time per epoch:  0.09832\n",
            "Epoch:   460 || Loss:  0.29704 || Correct    50 || Time per epoch:  0.09830\n",
            "Epoch:   470 || Loss:  0.30774 || Correct    50 || Time per epoch:  0.09857\n",
            "Epoch:   480 || Loss:  0.02018 || Correct    50 || Time per epoch:  0.09722\n",
            "Epoch:   490 || Loss:  0.00950 || Correct    50 || Time per epoch:  0.09716\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd $DIR; PYTHONPATH=/content/$DIR python3 project/run_fast_tensor.py --BACKEND gpu --HIDDEN 100 --DATASET split --RATE 0.05"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDgG4XeBzoIb",
        "outputId": "da806b10-6b50-4efb-f97b-815ce86be85c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 100 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 8 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "Epoch:     0 || Loss:  6.75284 || Correct    31 || Time per epoch:  4.77605\n",
            "Epoch:    10 || Loss:  5.58277 || Correct    41 || Time per epoch:  1.97466\n",
            "Epoch:    20 || Loss:  6.68693 || Correct    38 || Time per epoch:  1.94805\n",
            "Epoch:    30 || Loss:  2.52563 || Correct    47 || Time per epoch:  1.87270\n",
            "Epoch:    40 || Loss:  3.09321 || Correct    49 || Time per epoch:  1.94237\n",
            "Epoch:    50 || Loss:  2.38445 || Correct    48 || Time per epoch:  1.86161\n",
            "Epoch:    60 || Loss:  2.05923 || Correct    50 || Time per epoch:  1.94432\n",
            "Epoch:    70 || Loss:  1.20019 || Correct    47 || Time per epoch:  1.86829\n",
            "Epoch:    80 || Loss:  2.14480 || Correct    50 || Time per epoch:  1.95073\n",
            "Epoch:    90 || Loss:  2.35514 || Correct    50 || Time per epoch:  1.92010\n",
            "Epoch:   100 || Loss:  0.76116 || Correct    48 || Time per epoch:  1.89306\n",
            "Epoch:   110 || Loss:  0.76636 || Correct    49 || Time per epoch:  1.94913\n",
            "Epoch:   120 || Loss:  1.21298 || Correct    50 || Time per epoch:  1.86073\n",
            "Epoch:   130 || Loss:  0.87785 || Correct    50 || Time per epoch:  1.94288\n",
            "Epoch:   140 || Loss:  0.89645 || Correct    50 || Time per epoch:  1.85993\n",
            "Epoch:   150 || Loss:  1.14349 || Correct    50 || Time per epoch:  1.94711\n",
            "Epoch:   160 || Loss:  0.88506 || Correct    50 || Time per epoch:  1.86889\n",
            "Epoch:   170 || Loss:  1.31130 || Correct    50 || Time per epoch:  1.92485\n",
            "Epoch:   180 || Loss:  0.46336 || Correct    50 || Time per epoch:  1.94373\n",
            "Epoch:   190 || Loss:  0.37956 || Correct    50 || Time per epoch:  1.86076\n",
            "Epoch:   200 || Loss:  0.51409 || Correct    50 || Time per epoch:  1.94921\n",
            "Epoch:   210 || Loss:  0.80199 || Correct    50 || Time per epoch:  1.86188\n",
            "Epoch:   220 || Loss:  0.21237 || Correct    50 || Time per epoch:  1.93738\n",
            "Epoch:   230 || Loss:  0.90014 || Correct    50 || Time per epoch:  1.86324\n",
            "Epoch:   240 || Loss:  0.23754 || Correct    50 || Time per epoch:  1.95168\n",
            "Epoch:   250 || Loss:  0.48261 || Correct    50 || Time per epoch:  1.92656\n",
            "Epoch:   260 || Loss:  0.58314 || Correct    50 || Time per epoch:  1.87206\n",
            "Epoch:   270 || Loss:  0.24448 || Correct    50 || Time per epoch:  1.96329\n",
            "Epoch:   280 || Loss:  0.10696 || Correct    50 || Time per epoch:  1.87595\n",
            "Epoch:   290 || Loss:  0.03216 || Correct    50 || Time per epoch:  1.94253\n",
            "Epoch:   300 || Loss:  0.44955 || Correct    50 || Time per epoch:  1.86138\n",
            "Epoch:   310 || Loss:  0.09414 || Correct    50 || Time per epoch:  1.95082\n",
            "Epoch:   320 || Loss:  0.46210 || Correct    50 || Time per epoch:  1.92245\n",
            "Epoch:   330 || Loss:  0.46836 || Correct    50 || Time per epoch:  1.87132\n",
            "Epoch:   340 || Loss:  0.07113 || Correct    50 || Time per epoch:  1.95224\n",
            "Epoch:   350 || Loss:  0.61147 || Correct    50 || Time per epoch:  1.86682\n",
            "Epoch:   360 || Loss:  0.49413 || Correct    50 || Time per epoch:  1.94391\n",
            "Epoch:   370 || Loss:  0.24420 || Correct    50 || Time per epoch:  1.86453\n",
            "Epoch:   380 || Loss:  0.40807 || Correct    50 || Time per epoch:  1.92774\n",
            "Epoch:   390 || Loss:  0.22841 || Correct    50 || Time per epoch:  1.86420\n",
            "Epoch:   400 || Loss:  0.20728 || Correct    50 || Time per epoch:  1.92873\n",
            "Epoch:   410 || Loss:  0.05500 || Correct    50 || Time per epoch:  1.94213\n",
            "Epoch:   420 || Loss:  0.61322 || Correct    50 || Time per epoch:  1.85387\n",
            "Epoch:   430 || Loss:  0.24672 || Correct    50 || Time per epoch:  1.95433\n",
            "Epoch:   440 || Loss:  0.13920 || Correct    50 || Time per epoch:  1.85722\n",
            "Epoch:   450 || Loss:  0.35801 || Correct    50 || Time per epoch:  1.93630\n",
            "Epoch:   460 || Loss:  0.03450 || Correct    50 || Time per epoch:  1.86143\n",
            "Epoch:   470 || Loss:  0.11887 || Correct    50 || Time per epoch:  1.94299\n",
            "Epoch:   480 || Loss:  0.18061 || Correct    50 || Time per epoch:  1.89205\n",
            "Epoch:   490 || Loss:  0.10301 || Correct    50 || Time per epoch:  1.90425\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd $DIR; PYTHONPATH=/content/$DIR python3 project/run_fast_tensor.py --BACKEND cpu --HIDDEN 500 --DATASET split --RATE 0.05"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mYDdMItCDel",
        "outputId": "e27abca3-eb57-4e8e-9483-b74004fc16bc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:     0 || Loss:  26.63657 || Correct    39 || Time per epoch:  18.94309\n",
            "Epoch:    10 || Loss:  4.42665 || Correct    44 || Time per epoch:  0.83532\n",
            "Epoch:    20 || Loss:  1.08549 || Correct    49 || Time per epoch:  0.82688\n",
            "Epoch:    30 || Loss:  2.25921 || Correct    48 || Time per epoch:  0.74359\n",
            "Epoch:    40 || Loss:  2.47335 || Correct    44 || Time per epoch:  0.84621\n",
            "Epoch:    50 || Loss:  0.73759 || Correct    49 || Time per epoch:  0.79610\n",
            "Epoch:    60 || Loss:  0.32806 || Correct    49 || Time per epoch:  0.77416\n",
            "Epoch:    70 || Loss:  1.79367 || Correct    49 || Time per epoch:  0.84081\n",
            "Epoch:    80 || Loss:  0.80014 || Correct    49 || Time per epoch:  0.78349\n",
            "Epoch:    90 || Loss:  0.09830 || Correct    47 || Time per epoch:  0.79658\n",
            "Epoch:   100 || Loss:  1.13797 || Correct    49 || Time per epoch:  0.84541\n",
            "Epoch:   110 || Loss:  0.03126 || Correct    49 || Time per epoch:  0.76781\n",
            "Epoch:   120 || Loss:  0.13515 || Correct    49 || Time per epoch:  0.80149\n",
            "Epoch:   130 || Loss:  0.98313 || Correct    50 || Time per epoch:  0.84891\n",
            "Epoch:   140 || Loss:  1.70810 || Correct    47 || Time per epoch:  0.75008\n",
            "Epoch:   150 || Loss:  0.00314 || Correct    48 || Time per epoch:  0.81528\n",
            "Epoch:   160 || Loss:  1.22005 || Correct    50 || Time per epoch:  0.84248\n",
            "Epoch:   170 || Loss:  1.28310 || Correct    49 || Time per epoch:  0.72654\n",
            "Epoch:   180 || Loss:  0.05553 || Correct    49 || Time per epoch:  0.83338\n",
            "Epoch:   190 || Loss:  0.22367 || Correct    49 || Time per epoch:  0.83317\n",
            "Epoch:   200 || Loss:  0.76648 || Correct    49 || Time per epoch:  0.71882\n",
            "Epoch:   210 || Loss:  0.28571 || Correct    49 || Time per epoch:  0.82922\n",
            "Epoch:   220 || Loss:  0.96858 || Correct    49 || Time per epoch:  0.82905\n",
            "Epoch:   230 || Loss:  0.47136 || Correct    49 || Time per epoch:  0.72687\n",
            "Epoch:   240 || Loss:  1.50203 || Correct    48 || Time per epoch:  0.84422\n",
            "Epoch:   250 || Loss:  0.76940 || Correct    49 || Time per epoch:  0.83380\n",
            "Epoch:   260 || Loss:  0.01824 || Correct    49 || Time per epoch:  0.72818\n",
            "Epoch:   270 || Loss:  0.00545 || Correct    50 || Time per epoch:  0.83683\n",
            "Epoch:   280 || Loss:  0.46591 || Correct    50 || Time per epoch:  0.83258\n",
            "Epoch:   290 || Loss:  0.06448 || Correct    49 || Time per epoch:  0.72664\n",
            "Epoch:   300 || Loss:  0.07227 || Correct    48 || Time per epoch:  0.83250\n",
            "Epoch:   310 || Loss:  1.08556 || Correct    49 || Time per epoch:  0.83873\n",
            "Epoch:   320 || Loss:  0.55761 || Correct    50 || Time per epoch:  0.72817\n",
            "Epoch:   330 || Loss:  0.77213 || Correct    49 || Time per epoch:  0.83462\n",
            "Epoch:   340 || Loss:  0.12404 || Correct    49 || Time per epoch:  0.83629\n",
            "Epoch:   350 || Loss:  0.47125 || Correct    49 || Time per epoch:  0.73288\n",
            "Epoch:   360 || Loss:  0.11341 || Correct    49 || Time per epoch:  0.83604\n",
            "Epoch:   370 || Loss:  0.53074 || Correct    49 || Time per epoch:  0.80545\n",
            "Epoch:   380 || Loss:  0.02952 || Correct    49 || Time per epoch:  0.74958\n",
            "Epoch:   390 || Loss:  0.08037 || Correct    50 || Time per epoch:  0.83091\n",
            "Epoch:   400 || Loss:  0.10601 || Correct    49 || Time per epoch:  0.78214\n",
            "Epoch:   410 || Loss:  0.62870 || Correct    49 || Time per epoch:  0.75907\n",
            "Epoch:   420 || Loss:  0.22065 || Correct    50 || Time per epoch:  0.82327\n",
            "Epoch:   430 || Loss:  0.74018 || Correct    49 || Time per epoch:  0.76078\n",
            "Epoch:   440 || Loss:  0.65406 || Correct    49 || Time per epoch:  0.77645\n",
            "Epoch:   450 || Loss:  0.23989 || Correct    50 || Time per epoch:  0.82311\n",
            "Epoch:   460 || Loss:  0.06309 || Correct    50 || Time per epoch:  0.71788\n",
            "Epoch:   470 || Loss:  0.00118 || Correct    50 || Time per epoch:  0.82443\n",
            "Epoch:   480 || Loss:  0.23151 || Correct    50 || Time per epoch:  0.82296\n",
            "Epoch:   490 || Loss:  0.52680 || Correct    50 || Time per epoch:  0.72478\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd $DIR; PYTHONPATH=/content/$DIR python3 project/run_fast_tensor.py --BACKEND gpu --HIDDEN 500 --DATASET split --RATE 0.05"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hDHr98BCHUT",
        "outputId": "bff255bb-9ac2-4424-ae5c-944ab9536544"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "Epoch:     0 || Loss:  42.14486 || Correct    35 || Time per epoch:  5.52751\n",
            "Epoch:    10 || Loss:  1.49197 || Correct    48 || Time per epoch:  2.54132\n",
            "Epoch:    20 || Loss:  0.27354 || Correct    50 || Time per epoch:  2.51078\n",
            "Epoch:    30 || Loss:  0.11967 || Correct    50 || Time per epoch:  2.51609\n",
            "Epoch:    40 || Loss:  0.20061 || Correct    50 || Time per epoch:  2.48845\n",
            "Epoch:    50 || Loss:  0.04813 || Correct    50 || Time per epoch:  2.51117\n",
            "Epoch:    60 || Loss:  0.43111 || Correct    50 || Time per epoch:  2.50816\n",
            "Epoch:    70 || Loss:  0.03283 || Correct    50 || Time per epoch:  2.52371\n",
            "Epoch:    80 || Loss:  0.18903 || Correct    50 || Time per epoch:  2.51416\n",
            "Epoch:    90 || Loss:  0.06027 || Correct    50 || Time per epoch:  2.50389\n",
            "Epoch:   100 || Loss:  0.24614 || Correct    50 || Time per epoch:  2.51252\n",
            "Epoch:   110 || Loss:  0.02680 || Correct    50 || Time per epoch:  2.50932\n",
            "Epoch:   120 || Loss:  0.04301 || Correct    50 || Time per epoch:  2.52006\n",
            "Epoch:   130 || Loss:  0.06987 || Correct    50 || Time per epoch:  2.54098\n",
            "Epoch:   140 || Loss:  0.09600 || Correct    50 || Time per epoch:  2.54096\n",
            "Epoch:   150 || Loss:  0.06840 || Correct    50 || Time per epoch:  2.51686\n",
            "Epoch:   160 || Loss:  0.09925 || Correct    50 || Time per epoch:  2.51465\n",
            "Epoch:   170 || Loss:  0.03967 || Correct    50 || Time per epoch:  2.51075\n",
            "Epoch:   180 || Loss:  0.07584 || Correct    50 || Time per epoch:  2.50160\n",
            "Epoch:   190 || Loss:  0.07697 || Correct    50 || Time per epoch:  2.53213\n",
            "Epoch:   200 || Loss:  0.04652 || Correct    50 || Time per epoch:  2.51394\n",
            "Epoch:   210 || Loss:  0.11926 || Correct    50 || Time per epoch:  2.48633\n",
            "Epoch:   220 || Loss:  0.13272 || Correct    50 || Time per epoch:  2.49763\n",
            "Epoch:   230 || Loss:  0.05600 || Correct    50 || Time per epoch:  2.53263\n",
            "Epoch:   240 || Loss:  0.04916 || Correct    50 || Time per epoch:  2.49847\n",
            "Epoch:   250 || Loss:  0.02100 || Correct    50 || Time per epoch:  2.48631\n",
            "Epoch:   260 || Loss:  0.01018 || Correct    50 || Time per epoch:  2.53555\n",
            "Epoch:   270 || Loss:  0.07433 || Correct    50 || Time per epoch:  2.49700\n",
            "Epoch:   280 || Loss:  0.08836 || Correct    50 || Time per epoch:  2.51607\n",
            "Epoch:   290 || Loss:  0.05976 || Correct    50 || Time per epoch:  2.53303\n",
            "Epoch:   300 || Loss:  0.08221 || Correct    50 || Time per epoch:  2.52686\n",
            "Epoch:   310 || Loss:  0.03649 || Correct    50 || Time per epoch:  2.51033\n",
            "Epoch:   320 || Loss:  0.02947 || Correct    50 || Time per epoch:  2.49012\n",
            "Epoch:   330 || Loss:  0.03893 || Correct    50 || Time per epoch:  2.48588\n",
            "Epoch:   340 || Loss:  0.04478 || Correct    50 || Time per epoch:  2.49812\n",
            "Epoch:   350 || Loss:  0.04120 || Correct    50 || Time per epoch:  2.49944\n",
            "Epoch:   360 || Loss:  0.02590 || Correct    50 || Time per epoch:  2.49253\n",
            "Epoch:   370 || Loss:  0.02346 || Correct    50 || Time per epoch:  2.48747\n",
            "Epoch:   380 || Loss:  0.06421 || Correct    50 || Time per epoch:  2.48179\n",
            "Epoch:   390 || Loss:  0.01049 || Correct    50 || Time per epoch:  2.48777\n",
            "Epoch:   400 || Loss:  0.06296 || Correct    50 || Time per epoch:  2.48992\n",
            "Epoch:   410 || Loss:  0.02813 || Correct    50 || Time per epoch:  2.49037\n",
            "Epoch:   420 || Loss:  0.07447 || Correct    50 || Time per epoch:  2.48463\n",
            "Epoch:   430 || Loss:  0.06173 || Correct    50 || Time per epoch:  2.49808\n",
            "Epoch:   440 || Loss:  0.04518 || Correct    50 || Time per epoch:  2.49432\n",
            "Epoch:   450 || Loss:  0.07053 || Correct    50 || Time per epoch:  2.47132\n",
            "Epoch:   460 || Loss:  0.03408 || Correct    50 || Time per epoch:  2.48783\n",
            "Epoch:   470 || Loss:  0.02356 || Correct    50 || Time per epoch:  2.49280\n",
            "Epoch:   480 || Loss:  0.06007 || Correct    50 || Time per epoch:  2.49457\n",
            "Epoch:   490 || Loss:  0.02870 || Correct    50 || Time per epoch:  2.51160\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split"
      ],
      "metadata": {
        "id": "m1P6B0Otzcd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd $DIR; PYTHONPATH=/content/$DIR python3 project/run_fast_tensor.py --BACKEND cpu --HIDDEN 100 --DATASET split --RATE 0.05"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmxLfsMmM3RZ",
        "outputId": "434b0c49-cb0d-4eaf-ed31-2e859a09cc16"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:     0 || Loss:  4.07173 || Correct    32 || Time per epoch:  18.16308\n",
            "Epoch:    10 || Loss:  4.52326 || Correct    39 || Time per epoch:  0.09813\n",
            "Epoch:    20 || Loss:  5.17273 || Correct    46 || Time per epoch:  0.09768\n",
            "Epoch:    30 || Loss:  3.45568 || Correct    45 || Time per epoch:  0.09738\n",
            "Epoch:    40 || Loss:  1.34912 || Correct    47 || Time per epoch:  0.09745\n",
            "Epoch:    50 || Loss:  2.84589 || Correct    50 || Time per epoch:  0.17305\n",
            "Epoch:    60 || Loss:  1.40761 || Correct    47 || Time per epoch:  0.13012\n",
            "Epoch:    70 || Loss:  1.40857 || Correct    47 || Time per epoch:  0.09842\n",
            "Epoch:    80 || Loss:  1.10346 || Correct    46 || Time per epoch:  0.09778\n",
            "Epoch:    90 || Loss:  2.20721 || Correct    46 || Time per epoch:  0.09666\n",
            "Epoch:   100 || Loss:  1.50759 || Correct    49 || Time per epoch:  0.09809\n",
            "Epoch:   110 || Loss:  1.46235 || Correct    47 || Time per epoch:  0.10250\n",
            "Epoch:   120 || Loss:  1.18130 || Correct    48 || Time per epoch:  0.09846\n",
            "Epoch:   130 || Loss:  0.75492 || Correct    48 || Time per epoch:  0.09764\n",
            "Epoch:   140 || Loss:  1.85645 || Correct    47 || Time per epoch:  0.09763\n",
            "Epoch:   150 || Loss:  0.62259 || Correct    49 || Time per epoch:  0.09761\n",
            "Epoch:   160 || Loss:  0.86316 || Correct    47 || Time per epoch:  0.13687\n",
            "Epoch:   170 || Loss:  0.42979 || Correct    48 || Time per epoch:  0.16689\n",
            "Epoch:   180 || Loss:  0.95437 || Correct    50 || Time per epoch:  0.09984\n",
            "Epoch:   190 || Loss:  1.34532 || Correct    47 || Time per epoch:  0.09737\n",
            "Epoch:   200 || Loss:  1.99121 || Correct    47 || Time per epoch:  0.09764\n",
            "Epoch:   210 || Loss:  1.53018 || Correct    50 || Time per epoch:  0.09748\n",
            "Epoch:   220 || Loss:  0.65905 || Correct    48 || Time per epoch:  0.09737\n",
            "Epoch:   230 || Loss:  1.25711 || Correct    49 || Time per epoch:  0.09765\n",
            "Epoch:   240 || Loss:  1.03930 || Correct    49 || Time per epoch:  0.09713\n",
            "Epoch:   250 || Loss:  0.16117 || Correct    50 || Time per epoch:  0.09767\n",
            "Epoch:   260 || Loss:  0.75199 || Correct    49 || Time per epoch:  0.09775\n",
            "Epoch:   270 || Loss:  0.90745 || Correct    50 || Time per epoch:  0.09921\n",
            "Epoch:   280 || Loss:  1.32554 || Correct    50 || Time per epoch:  0.16072\n",
            "Epoch:   290 || Loss:  1.45179 || Correct    50 || Time per epoch:  0.13271\n",
            "Epoch:   300 || Loss:  0.36491 || Correct    49 || Time per epoch:  0.09819\n",
            "Epoch:   310 || Loss:  0.60159 || Correct    50 || Time per epoch:  0.09739\n",
            "Epoch:   320 || Loss:  1.08264 || Correct    50 || Time per epoch:  0.09821\n",
            "Epoch:   330 || Loss:  0.14492 || Correct    49 || Time per epoch:  0.09664\n",
            "Epoch:   340 || Loss:  0.92786 || Correct    50 || Time per epoch:  0.09727\n",
            "Epoch:   350 || Loss:  0.94650 || Correct    50 || Time per epoch:  0.09722\n",
            "Epoch:   360 || Loss:  0.73996 || Correct    50 || Time per epoch:  0.09757\n",
            "Epoch:   370 || Loss:  1.17886 || Correct    47 || Time per epoch:  0.09731\n",
            "Epoch:   380 || Loss:  0.39339 || Correct    49 || Time per epoch:  0.09760\n",
            "Epoch:   390 || Loss:  0.55229 || Correct    49 || Time per epoch:  0.12638\n",
            "Epoch:   400 || Loss:  1.31742 || Correct    49 || Time per epoch:  0.17409\n",
            "Epoch:   410 || Loss:  1.05392 || Correct    48 || Time per epoch:  0.09765\n",
            "Epoch:   420 || Loss:  0.86586 || Correct    50 || Time per epoch:  0.09825\n",
            "Epoch:   430 || Loss:  0.31504 || Correct    50 || Time per epoch:  0.09697\n",
            "Epoch:   440 || Loss:  0.93252 || Correct    50 || Time per epoch:  0.09739\n",
            "Epoch:   450 || Loss:  0.50321 || Correct    50 || Time per epoch:  0.10389\n",
            "Epoch:   460 || Loss:  0.71669 || Correct    50 || Time per epoch:  0.09961\n",
            "Epoch:   470 || Loss:  0.52318 || Correct    50 || Time per epoch:  0.09718\n",
            "Epoch:   480 || Loss:  0.44780 || Correct    49 || Time per epoch:  0.09741\n",
            "Epoch:   490 || Loss:  0.09766 || Correct    50 || Time per epoch:  0.09717\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd $DIR; PYTHONPATH=/content/$DIR python3 project/run_fast_tensor.py --BACKEND gpu --HIDDEN 100 --DATASET split --RATE 0.05"
      ],
      "metadata": {
        "id": "FY8Q4MqEzvGW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "453072e1-d4da-46a8-bb95-f2d831937bf5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 100 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 8 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "Epoch:     0 || Loss:  7.29856 || Correct    30 || Time per epoch:  5.68361\n",
            "Epoch:    10 || Loss:  4.96110 || Correct    40 || Time per epoch:  1.88098\n",
            "Epoch:    20 || Loss:  9.74443 || Correct    25 || Time per epoch:  1.98892\n",
            "Epoch:    30 || Loss:  4.84711 || Correct    39 || Time per epoch:  1.87550\n",
            "Epoch:    40 || Loss:  4.40643 || Correct    43 || Time per epoch:  1.93422\n",
            "Epoch:    50 || Loss:  2.98539 || Correct    44 || Time per epoch:  1.94600\n",
            "Epoch:    60 || Loss:  4.65592 || Correct    43 || Time per epoch:  1.87556\n",
            "Epoch:    70 || Loss:  3.23241 || Correct    49 || Time per epoch:  1.93032\n",
            "Epoch:    80 || Loss:  1.86293 || Correct    47 || Time per epoch:  1.86646\n",
            "Epoch:    90 || Loss:  2.35521 || Correct    48 || Time per epoch:  1.94626\n",
            "Epoch:   100 || Loss:  0.99056 || Correct    46 || Time per epoch:  1.87222\n",
            "Epoch:   110 || Loss:  2.53351 || Correct    48 || Time per epoch:  1.95791\n",
            "Epoch:   120 || Loss:  2.38217 || Correct    46 || Time per epoch:  1.91514\n",
            "Epoch:   130 || Loss:  1.68064 || Correct    48 || Time per epoch:  1.90399\n",
            "Epoch:   140 || Loss:  0.47471 || Correct    49 || Time per epoch:  1.95988\n",
            "Epoch:   150 || Loss:  1.13329 || Correct    48 || Time per epoch:  1.87276\n",
            "Epoch:   160 || Loss:  1.08500 || Correct    49 || Time per epoch:  1.95246\n",
            "Epoch:   170 || Loss:  1.04436 || Correct    49 || Time per epoch:  1.86897\n",
            "Epoch:   180 || Loss:  1.11847 || Correct    48 || Time per epoch:  1.93738\n",
            "Epoch:   190 || Loss:  0.76054 || Correct    49 || Time per epoch:  1.91312\n",
            "Epoch:   200 || Loss:  1.13712 || Correct    49 || Time per epoch:  1.89972\n",
            "Epoch:   210 || Loss:  0.48208 || Correct    49 || Time per epoch:  1.94485\n",
            "Epoch:   220 || Loss:  0.53602 || Correct    49 || Time per epoch:  1.86999\n",
            "Epoch:   230 || Loss:  0.99934 || Correct    49 || Time per epoch:  1.94432\n",
            "Epoch:   240 || Loss:  1.87460 || Correct    49 || Time per epoch:  1.87323\n",
            "Epoch:   250 || Loss:  1.02500 || Correct    50 || Time per epoch:  1.94070\n",
            "Epoch:   260 || Loss:  0.70516 || Correct    49 || Time per epoch:  1.87676\n",
            "Epoch:   270 || Loss:  1.05425 || Correct    50 || Time per epoch:  1.92227\n",
            "Epoch:   280 || Loss:  1.46647 || Correct    50 || Time per epoch:  1.94358\n",
            "Epoch:   290 || Loss:  1.21522 || Correct    50 || Time per epoch:  1.86195\n",
            "Epoch:   300 || Loss:  0.71102 || Correct    49 || Time per epoch:  1.94752\n",
            "Epoch:   310 || Loss:  0.79022 || Correct    49 || Time per epoch:  1.87100\n",
            "Epoch:   320 || Loss:  1.34444 || Correct    49 || Time per epoch:  1.94841\n",
            "Epoch:   330 || Loss:  1.75439 || Correct    49 || Time per epoch:  1.88745\n",
            "Epoch:   340 || Loss:  0.69900 || Correct    50 || Time per epoch:  1.93149\n",
            "Epoch:   350 || Loss:  0.05217 || Correct    49 || Time per epoch:  1.94405\n",
            "Epoch:   360 || Loss:  0.38922 || Correct    50 || Time per epoch:  1.86621\n",
            "Epoch:   370 || Loss:  0.87756 || Correct    50 || Time per epoch:  1.94147\n",
            "Epoch:   380 || Loss:  1.28520 || Correct    49 || Time per epoch:  1.86340\n",
            "Epoch:   390 || Loss:  1.08639 || Correct    50 || Time per epoch:  1.96440\n",
            "Epoch:   400 || Loss:  0.38072 || Correct    50 || Time per epoch:  1.87549\n",
            "Epoch:   410 || Loss:  1.29022 || Correct    49 || Time per epoch:  1.94588\n",
            "Epoch:   420 || Loss:  0.73392 || Correct    50 || Time per epoch:  1.95597\n",
            "Epoch:   430 || Loss:  0.64191 || Correct    50 || Time per epoch:  1.88988\n",
            "Epoch:   440 || Loss:  0.59425 || Correct    50 || Time per epoch:  1.99555\n",
            "Epoch:   450 || Loss:  1.16145 || Correct    49 || Time per epoch:  1.87641\n",
            "Epoch:   460 || Loss:  0.18022 || Correct    49 || Time per epoch:  1.96158\n",
            "Epoch:   470 || Loss:  1.76201 || Correct    49 || Time per epoch:  1.91591\n",
            "Epoch:   480 || Loss:  0.85149 || Correct    50 || Time per epoch:  1.91267\n",
            "Epoch:   490 || Loss:  0.42668 || Correct    50 || Time per epoch:  1.97247\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XOR"
      ],
      "metadata": {
        "id": "PPVGONIWzsq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cd $DIR; PYTHONPATH=/content/$DIR python3 project/run_fast_tensor.py --BACKEND cpu --HIDDEN 100 --DATASET xor --RATE 0.05"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cesaZyiOO66j",
        "outputId": "2e373a90-0493-4c7f-d7ab-87bdd8deea5c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:     0 || Loss:  6.80791 || Correct    28 || Time per epoch:  18.22354\n",
            "Epoch:    10 || Loss:  4.28319 || Correct    37 || Time per epoch:  0.09793\n",
            "Epoch:    20 || Loss:  2.93311 || Correct    44 || Time per epoch:  0.09738\n",
            "Epoch:    30 || Loss:  3.23911 || Correct    44 || Time per epoch:  0.09757\n",
            "Epoch:    40 || Loss:  2.63329 || Correct    45 || Time per epoch:  0.10524\n",
            "Epoch:    50 || Loss:  2.51675 || Correct    45 || Time per epoch:  0.17248\n",
            "Epoch:    60 || Loss:  2.72185 || Correct    45 || Time per epoch:  0.12250\n",
            "Epoch:    70 || Loss:  1.28917 || Correct    46 || Time per epoch:  0.09658\n",
            "Epoch:    80 || Loss:  1.48718 || Correct    46 || Time per epoch:  0.09691\n",
            "Epoch:    90 || Loss:  0.74941 || Correct    46 || Time per epoch:  0.09767\n",
            "Epoch:   100 || Loss:  2.23547 || Correct    46 || Time per epoch:  0.09663\n",
            "Epoch:   110 || Loss:  1.35189 || Correct    45 || Time per epoch:  0.09711\n",
            "Epoch:   120 || Loss:  1.30326 || Correct    46 || Time per epoch:  0.09703\n",
            "Epoch:   130 || Loss:  3.71375 || Correct    46 || Time per epoch:  0.09878\n",
            "Epoch:   140 || Loss:  2.33340 || Correct    47 || Time per epoch:  0.10197\n",
            "Epoch:   150 || Loss:  1.69693 || Correct    47 || Time per epoch:  0.10087\n",
            "Epoch:   160 || Loss:  2.47193 || Correct    47 || Time per epoch:  0.15403\n",
            "Epoch:   170 || Loss:  1.62141 || Correct    46 || Time per epoch:  0.15398\n",
            "Epoch:   180 || Loss:  0.80703 || Correct    47 || Time per epoch:  0.09863\n",
            "Epoch:   190 || Loss:  2.30713 || Correct    47 || Time per epoch:  0.09952\n",
            "Epoch:   200 || Loss:  1.80140 || Correct    47 || Time per epoch:  0.09861\n",
            "Epoch:   210 || Loss:  0.90898 || Correct    47 || Time per epoch:  0.10057\n",
            "Epoch:   220 || Loss:  2.64474 || Correct    47 || Time per epoch:  0.09898\n",
            "Epoch:   230 || Loss:  0.48834 || Correct    47 || Time per epoch:  0.10073\n",
            "Epoch:   240 || Loss:  1.31547 || Correct    48 || Time per epoch:  0.09842\n",
            "Epoch:   250 || Loss:  2.15667 || Correct    47 || Time per epoch:  0.09809\n",
            "Epoch:   260 || Loss:  0.81131 || Correct    47 || Time per epoch:  0.09914\n",
            "Epoch:   270 || Loss:  2.26540 || Correct    48 || Time per epoch:  0.12321\n",
            "Epoch:   280 || Loss:  0.20556 || Correct    49 || Time per epoch:  0.17621\n",
            "Epoch:   290 || Loss:  2.12707 || Correct    48 || Time per epoch:  0.09695\n",
            "Epoch:   300 || Loss:  0.49326 || Correct    47 || Time per epoch:  0.09731\n",
            "Epoch:   310 || Loss:  1.31325 || Correct    47 || Time per epoch:  0.09725\n",
            "Epoch:   320 || Loss:  2.58391 || Correct    47 || Time per epoch:  0.09667\n",
            "Epoch:   330 || Loss:  0.64292 || Correct    47 || Time per epoch:  0.09721\n",
            "Epoch:   340 || Loss:  0.66021 || Correct    49 || Time per epoch:  0.09732\n",
            "Epoch:   350 || Loss:  0.74039 || Correct    48 || Time per epoch:  0.09733\n",
            "Epoch:   360 || Loss:  1.98287 || Correct    48 || Time per epoch:  0.09703\n",
            "Epoch:   370 || Loss:  0.73640 || Correct    49 || Time per epoch:  0.09780\n",
            "Epoch:   380 || Loss:  1.76571 || Correct    47 || Time per epoch:  0.09761\n",
            "Epoch:   390 || Loss:  1.45749 || Correct    49 || Time per epoch:  0.16815\n",
            "Epoch:   400 || Loss:  1.29377 || Correct    48 || Time per epoch:  0.14178\n",
            "Epoch:   410 || Loss:  0.69903 || Correct    48 || Time per epoch:  0.10009\n",
            "Epoch:   420 || Loss:  1.29314 || Correct    49 || Time per epoch:  0.09747\n",
            "Epoch:   430 || Loss:  1.73983 || Correct    48 || Time per epoch:  0.09669\n",
            "Epoch:   440 || Loss:  0.28013 || Correct    49 || Time per epoch:  0.09689\n",
            "Epoch:   450 || Loss:  0.39230 || Correct    49 || Time per epoch:  0.09722\n",
            "Epoch:   460 || Loss:  0.27196 || Correct    49 || Time per epoch:  0.09699\n",
            "Epoch:   470 || Loss:  0.83664 || Correct    49 || Time per epoch:  0.09669\n",
            "Epoch:   480 || Loss:  0.10319 || Correct    49 || Time per epoch:  0.09758\n",
            "Epoch:   490 || Loss:  0.78115 || Correct    49 || Time per epoch:  0.09673\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd $DIR; PYTHONPATH=/content/$DIR python3 project/run_fast_tensor.py --BACKEND gpu --HIDDEN 100 --DATASET xor --RATE 0.05"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLAA9dUTRl7l",
        "outputId": "17c171d1-9669-4b3b-d355-062cb81a12f2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 100 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 7 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 8 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "Epoch:     0 || Loss:  6.60616 || Correct    29 || Time per epoch:  4.34647\n",
            "Epoch:    10 || Loss:  7.75637 || Correct    38 || Time per epoch:  1.92764\n",
            "Epoch:    20 || Loss:  4.08382 || Correct    40 || Time per epoch:  1.93153\n",
            "Epoch:    30 || Loss:  5.01938 || Correct    40 || Time per epoch:  1.97435\n",
            "Epoch:    40 || Loss:  2.83069 || Correct    47 || Time per epoch:  1.87607\n",
            "Epoch:    50 || Loss:  3.72208 || Correct    43 || Time per epoch:  1.95428\n",
            "Epoch:    60 || Loss:  2.82434 || Correct    45 || Time per epoch:  1.88109\n",
            "Epoch:    70 || Loss:  1.34516 || Correct    47 || Time per epoch:  1.94866\n",
            "Epoch:    80 || Loss:  2.56193 || Correct    50 || Time per epoch:  1.95371\n",
            "Epoch:    90 || Loss:  1.72377 || Correct    46 || Time per epoch:  1.88983\n",
            "Epoch:   100 || Loss:  1.76068 || Correct    48 || Time per epoch:  1.96065\n",
            "Epoch:   110 || Loss:  2.22888 || Correct    49 || Time per epoch:  1.89393\n",
            "Epoch:   120 || Loss:  1.66461 || Correct    49 || Time per epoch:  1.95306\n",
            "Epoch:   130 || Loss:  1.10404 || Correct    50 || Time per epoch:  1.91725\n",
            "Epoch:   140 || Loss:  1.11320 || Correct    48 || Time per epoch:  1.92632\n",
            "Epoch:   150 || Loss:  2.35142 || Correct    48 || Time per epoch:  1.96738\n",
            "Epoch:   160 || Loss:  0.88490 || Correct    49 || Time per epoch:  1.87565\n",
            "Epoch:   170 || Loss:  0.67688 || Correct    49 || Time per epoch:  1.95865\n",
            "Epoch:   180 || Loss:  0.86934 || Correct    49 || Time per epoch:  1.87605\n",
            "Epoch:   190 || Loss:  0.74325 || Correct    49 || Time per epoch:  1.95826\n",
            "Epoch:   200 || Loss:  0.92048 || Correct    49 || Time per epoch:  1.95339\n",
            "Epoch:   210 || Loss:  0.37536 || Correct    49 || Time per epoch:  1.87274\n",
            "Epoch:   220 || Loss:  0.62137 || Correct    49 || Time per epoch:  1.96424\n",
            "Epoch:   230 || Loss:  0.17097 || Correct    49 || Time per epoch:  1.87607\n",
            "Epoch:   240 || Loss:  0.38058 || Correct    49 || Time per epoch:  1.96488\n",
            "Epoch:   250 || Loss:  0.21541 || Correct    49 || Time per epoch:  1.89750\n",
            "Epoch:   260 || Loss:  0.83243 || Correct    49 || Time per epoch:  1.95606\n",
            "Epoch:   270 || Loss:  0.23149 || Correct    49 || Time per epoch:  1.95696\n",
            "Epoch:   280 || Loss:  0.43091 || Correct    49 || Time per epoch:  1.88882\n",
            "Epoch:   290 || Loss:  0.34242 || Correct    49 || Time per epoch:  1.96102\n",
            "Epoch:   300 || Loss:  1.77023 || Correct    49 || Time per epoch:  1.88385\n",
            "Epoch:   310 || Loss:  1.94001 || Correct    49 || Time per epoch:  1.98119\n",
            "Epoch:   320 || Loss:  0.46170 || Correct    49 || Time per epoch:  1.98320\n",
            "Epoch:   330 || Loss:  0.27046 || Correct    49 || Time per epoch:  1.88130\n",
            "Epoch:   340 || Loss:  0.30852 || Correct    49 || Time per epoch:  1.97567\n",
            "Epoch:   350 || Loss:  0.10542 || Correct    49 || Time per epoch:  1.87868\n",
            "Epoch:   360 || Loss:  0.15285 || Correct    49 || Time per epoch:  1.96293\n",
            "Epoch:   370 || Loss:  0.43318 || Correct    49 || Time per epoch:  1.92663\n",
            "Epoch:   380 || Loss:  0.31124 || Correct    49 || Time per epoch:  1.90558\n",
            "Epoch:   390 || Loss:  0.34115 || Correct    49 || Time per epoch:  1.95438\n",
            "Epoch:   400 || Loss:  0.01727 || Correct    49 || Time per epoch:  1.87678\n",
            "Epoch:   410 || Loss:  0.83704 || Correct    49 || Time per epoch:  1.96580\n",
            "Epoch:   420 || Loss:  1.68363 || Correct    49 || Time per epoch:  1.88321\n",
            "Epoch:   430 || Loss:  0.13303 || Correct    49 || Time per epoch:  1.95556\n",
            "Epoch:   440 || Loss:  0.07118 || Correct    48 || Time per epoch:  1.95816\n",
            "Epoch:   450 || Loss:  0.05079 || Correct    47 || Time per epoch:  1.89113\n",
            "Epoch:   460 || Loss:  1.45303 || Correct    49 || Time per epoch:  1.95944\n",
            "Epoch:   470 || Loss:  0.85109 || Correct    49 || Time per epoch:  1.89215\n",
            "Epoch:   480 || Loss:  0.05142 || Correct    49 || Time per epoch:  1.95261\n",
            "Epoch:   490 || Loss:  0.05718 || Correct    48 || Time per epoch:  1.88079\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd $DIR; PYTHONPATH=/content/$DIR python3 project/run_fast_tensor.py --BACKEND cpu --HIDDEN 500 --DATASET xor --RATE 0.05"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xy8MXUI76ncL",
        "outputId": "ab0c04c9-0e9b-43a7-f340-c3aca54bb4f7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:     0 || Loss:  76.92976 || Correct    32 || Time per epoch:  18.34954\n",
            "Epoch:    10 || Loss:  1.35926 || Correct    47 || Time per epoch:  0.73230\n",
            "Epoch:    20 || Loss:  3.21588 || Correct    46 || Time per epoch:  0.84166\n",
            "Epoch:    30 || Loss:  3.05700 || Correct    49 || Time per epoch:  0.86942\n",
            "Epoch:    40 || Loss:  3.17658 || Correct    47 || Time per epoch:  0.75742\n",
            "Epoch:    50 || Loss:  1.94909 || Correct    49 || Time per epoch:  0.82322\n",
            "Epoch:    60 || Loss:  0.93115 || Correct    49 || Time per epoch:  0.83951\n",
            "Epoch:    70 || Loss:  0.34140 || Correct    49 || Time per epoch:  0.73307\n",
            "Epoch:    80 || Loss:  0.66406 || Correct    48 || Time per epoch:  0.83509\n",
            "Epoch:    90 || Loss:  2.30551 || Correct    50 || Time per epoch:  0.84786\n",
            "Epoch:   100 || Loss:  3.61139 || Correct    47 || Time per epoch:  0.72473\n",
            "Epoch:   110 || Loss:  0.83126 || Correct    49 || Time per epoch:  0.83262\n",
            "Epoch:   120 || Loss:  1.97192 || Correct    50 || Time per epoch:  0.83627\n",
            "Epoch:   130 || Loss:  0.30938 || Correct    49 || Time per epoch:  0.72335\n",
            "Epoch:   140 || Loss:  0.52349 || Correct    49 || Time per epoch:  0.84278\n",
            "Epoch:   150 || Loss:  0.07128 || Correct    49 || Time per epoch:  0.83411\n",
            "Epoch:   160 || Loss:  0.53294 || Correct    49 || Time per epoch:  0.72746\n",
            "Epoch:   170 || Loss:  1.30419 || Correct    49 || Time per epoch:  0.83183\n",
            "Epoch:   180 || Loss:  0.70312 || Correct    49 || Time per epoch:  0.83272\n",
            "Epoch:   190 || Loss:  1.79597 || Correct    48 || Time per epoch:  0.72660\n",
            "Epoch:   200 || Loss:  0.90020 || Correct    49 || Time per epoch:  0.83923\n",
            "Epoch:   210 || Loss:  1.16867 || Correct    49 || Time per epoch:  0.83951\n",
            "Epoch:   220 || Loss:  1.54156 || Correct    50 || Time per epoch:  0.73978\n",
            "Epoch:   230 || Loss:  0.25539 || Correct    49 || Time per epoch:  0.83885\n",
            "Epoch:   240 || Loss:  0.21401 || Correct    49 || Time per epoch:  0.83789\n",
            "Epoch:   250 || Loss:  0.48800 || Correct    49 || Time per epoch:  0.72728\n",
            "Epoch:   260 || Loss:  1.88972 || Correct    48 || Time per epoch:  0.83628\n",
            "Epoch:   270 || Loss:  0.51600 || Correct    49 || Time per epoch:  0.84448\n",
            "Epoch:   280 || Loss:  0.02321 || Correct    50 || Time per epoch:  0.72758\n",
            "Epoch:   290 || Loss:  0.15047 || Correct    49 || Time per epoch:  0.84640\n",
            "Epoch:   300 || Loss:  0.21489 || Correct    49 || Time per epoch:  0.81544\n",
            "Epoch:   310 || Loss:  0.24901 || Correct    49 || Time per epoch:  0.74679\n",
            "Epoch:   320 || Loss:  0.43951 || Correct    50 || Time per epoch:  0.83898\n",
            "Epoch:   330 || Loss:  0.39011 || Correct    50 || Time per epoch:  0.80078\n",
            "Epoch:   340 || Loss:  0.19627 || Correct    50 || Time per epoch:  0.76696\n",
            "Epoch:   350 || Loss:  0.11633 || Correct    50 || Time per epoch:  0.83724\n",
            "Epoch:   360 || Loss:  0.48908 || Correct    49 || Time per epoch:  0.77567\n",
            "Epoch:   370 || Loss:  0.37118 || Correct    49 || Time per epoch:  0.79994\n",
            "Epoch:   380 || Loss:  0.19186 || Correct    49 || Time per epoch:  0.84142\n",
            "Epoch:   390 || Loss:  1.44289 || Correct    50 || Time per epoch:  0.73759\n",
            "Epoch:   400 || Loss:  1.84813 || Correct    48 || Time per epoch:  0.81961\n",
            "Epoch:   410 || Loss:  0.00150 || Correct    49 || Time per epoch:  0.82945\n",
            "Epoch:   420 || Loss:  0.04482 || Correct    49 || Time per epoch:  0.72373\n",
            "Epoch:   430 || Loss:  1.34708 || Correct    50 || Time per epoch:  0.83246\n",
            "Epoch:   440 || Loss:  0.39877 || Correct    49 || Time per epoch:  0.84474\n",
            "Epoch:   450 || Loss:  0.06718 || Correct    49 || Time per epoch:  0.72443\n",
            "Epoch:   460 || Loss:  0.01587 || Correct    50 || Time per epoch:  0.84396\n",
            "Epoch:   470 || Loss:  0.82684 || Correct    49 || Time per epoch:  0.83927\n",
            "Epoch:   480 || Loss:  0.23162 || Correct    50 || Time per epoch:  0.73161\n",
            "Epoch:   490 || Loss:  0.02331 || Correct    50 || Time per epoch:  0.84179\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd $DIR; PYTHONPATH=/content/$DIR python3 project/run_fast_tensor.py --BACKEND gpu --HIDDEN 500 --DATASET xor --RATE 0.05"
      ],
      "metadata": {
        "id": "krNrO-iHChaH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d75897ae-f99d-4074-cc8e-acf2112a7590"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 32 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 16 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 4 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:888: NumbaPerformanceWarning: \u001b[1mHost array used in CUDA kernel will incur copy overhead to/from device.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/dispatcher.py:536: NumbaPerformanceWarning: \u001b[1mGrid size 2 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n",
            "  warn(NumbaPerformanceWarning(msg))\n",
            "Epoch:     0 || Loss:  66.66105 || Correct    26 || Time per epoch:  4.56126\n",
            "Epoch:    10 || Loss:  1.39066 || Correct    45 || Time per epoch:  2.52134\n",
            "Epoch:    20 || Loss:  4.20055 || Correct    45 || Time per epoch:  2.54909\n",
            "Epoch:    30 || Loss:  1.63435 || Correct    44 || Time per epoch:  2.52698\n",
            "Epoch:    40 || Loss:  1.92903 || Correct    46 || Time per epoch:  2.51618\n",
            "Epoch:    50 || Loss:  1.86650 || Correct    50 || Time per epoch:  2.53035\n",
            "Epoch:    60 || Loss:  1.70978 || Correct    48 || Time per epoch:  2.53956\n",
            "Epoch:    70 || Loss:  0.82648 || Correct    50 || Time per epoch:  2.52403\n",
            "Epoch:    80 || Loss:  0.49825 || Correct    50 || Time per epoch:  2.51371\n",
            "Epoch:    90 || Loss:  0.45301 || Correct    50 || Time per epoch:  2.49895\n",
            "Epoch:   100 || Loss:  0.65924 || Correct    49 || Time per epoch:  2.49445\n",
            "Epoch:   110 || Loss:  0.85197 || Correct    50 || Time per epoch:  2.49448\n",
            "Epoch:   120 || Loss:  0.56903 || Correct    50 || Time per epoch:  2.48237\n",
            "Epoch:   130 || Loss:  0.20003 || Correct    50 || Time per epoch:  2.49669\n",
            "Epoch:   140 || Loss:  0.25957 || Correct    50 || Time per epoch:  2.48734\n",
            "Epoch:   150 || Loss:  0.69386 || Correct    50 || Time per epoch:  2.48817\n",
            "Epoch:   160 || Loss:  0.29471 || Correct    50 || Time per epoch:  2.48345\n",
            "Epoch:   170 || Loss:  0.41978 || Correct    50 || Time per epoch:  2.50649\n",
            "Epoch:   180 || Loss:  0.08283 || Correct    50 || Time per epoch:  2.50754\n",
            "Epoch:   190 || Loss:  0.97569 || Correct    50 || Time per epoch:  2.50714\n",
            "Epoch:   200 || Loss:  0.13449 || Correct    50 || Time per epoch:  2.49803\n",
            "Epoch:   210 || Loss:  0.61050 || Correct    50 || Time per epoch:  2.48258\n",
            "Epoch:   220 || Loss:  0.05742 || Correct    50 || Time per epoch:  2.49355\n",
            "Epoch:   230 || Loss:  0.16341 || Correct    50 || Time per epoch:  2.50641\n",
            "Epoch:   240 || Loss:  0.83830 || Correct    50 || Time per epoch:  2.50201\n",
            "Epoch:   250 || Loss:  0.56408 || Correct    50 || Time per epoch:  2.49401\n",
            "Epoch:   260 || Loss:  0.58886 || Correct    50 || Time per epoch:  2.49454\n",
            "Epoch:   270 || Loss:  0.61434 || Correct    50 || Time per epoch:  2.51382\n",
            "Epoch:   280 || Loss:  0.28423 || Correct    50 || Time per epoch:  2.52634\n",
            "Epoch:   290 || Loss:  0.75735 || Correct    50 || Time per epoch:  2.53270\n",
            "Epoch:   300 || Loss:  0.19432 || Correct    50 || Time per epoch:  2.50702\n",
            "Epoch:   310 || Loss:  0.20030 || Correct    50 || Time per epoch:  2.50111\n",
            "Epoch:   320 || Loss:  0.08164 || Correct    50 || Time per epoch:  2.49510\n",
            "Epoch:   330 || Loss:  0.88259 || Correct    49 || Time per epoch:  2.48761\n",
            "Epoch:   340 || Loss:  0.29611 || Correct    50 || Time per epoch:  2.50932\n",
            "Epoch:   350 || Loss:  0.02344 || Correct    50 || Time per epoch:  2.50552\n",
            "Epoch:   360 || Loss:  0.04437 || Correct    50 || Time per epoch:  2.54152\n",
            "Epoch:   370 || Loss:  0.07200 || Correct    50 || Time per epoch:  2.49936\n",
            "Epoch:   380 || Loss:  0.25661 || Correct    50 || Time per epoch:  2.49236\n",
            "Epoch:   390 || Loss:  0.19218 || Correct    50 || Time per epoch:  2.49501\n",
            "Epoch:   400 || Loss:  0.03950 || Correct    50 || Time per epoch:  2.50482\n",
            "Epoch:   410 || Loss:  0.12886 || Correct    50 || Time per epoch:  2.49639\n",
            "Epoch:   420 || Loss:  0.02836 || Correct    50 || Time per epoch:  2.49644\n",
            "Epoch:   430 || Loss:  0.02420 || Correct    50 || Time per epoch:  2.48882\n",
            "Epoch:   440 || Loss:  0.01050 || Correct    50 || Time per epoch:  2.50553\n",
            "Epoch:   450 || Loss:  0.52836 || Correct    50 || Time per epoch:  2.49256\n",
            "Epoch:   460 || Loss:  0.37681 || Correct    50 || Time per epoch:  2.52336\n",
            "Epoch:   470 || Loss:  0.08045 || Correct    50 || Time per epoch:  2.54079\n",
            "Epoch:   480 || Loss:  0.04526 || Correct    50 || Time per epoch:  2.54303\n",
            "Epoch:   490 || Loss:  0.34197 || Correct    50 || Time per epoch:  2.51295\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YL6k04O4w09S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}